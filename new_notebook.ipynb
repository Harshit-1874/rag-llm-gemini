{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becfb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"yolov9_paper.pdf\")\n",
    "data = loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316911b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents:  96\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# split data\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "\n",
    "print(\"Total number of documents: \",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a190c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05168594419956207,\n",
       " -0.030764883384108543,\n",
       " -0.03062233328819275,\n",
       " -0.02802734263241291,\n",
       " 0.01813093200325966]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "#Get an API key: \n",
    "# Head to https://ai.google.dev/gemini-api/docs/api-key to generate a Google AI API key. Paste in .env file\n",
    "\n",
    "# Embedding models: https://python.langchain.com/v0.1/docs/integrations/text_embedding/\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vector = embeddings.embed_query(\"hello, world!\")\n",
    "vector[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebed59c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7df4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"What is new in yolov9?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b682f586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv9: Learning What You Want to Learn\n",
      "Using Programmable Gradient Information\n",
      "Chien-Yao Wang1,2, I-Hau Yeh2, and Hong-Yuan Mark Liao1,2,3\n",
      "1Institute of Information Science, Academia Sinica, Taiwan\n",
      "2National Taipei University of Technology, Taiwan\n",
      "3Department of Information and Computer Engineering, Chung Yuan Christian University, Taiwan\n",
      "kinyiu@iis.sinica.edu.tw, ihyeh@emc.com.tw, and liao@iis.sinica.edu.tw\n",
      "Abstract\n",
      "Todayâ€™s deep learning methods focus on how to design\n",
      "the most appropriate objective functions so that the pre-\n",
      "diction results of the model can be closest to the ground\n",
      "truth. Meanwhile, an appropriate architecture that can\n",
      "facilitate acquisition of enough information for prediction\n",
      "has to be designed. Existing methods ignore a fact that\n",
      "when input data undergoes layer-by-layer feature extrac-\n",
      "tion and spatial transformation, large amount of informa-\n",
      "tion will be lost. This paper will delve into the important is-\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01f7fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0.3, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a9d965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eff63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70e018ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv9 introduces Programmable Gradient Information (PGI) to improve model accuracy by reducing information loss during training.  It also features Generalized ELAN (GELAN) for better parameter and computation management. These improvements make YOLOv9 a top-performing real-time object detector.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is new in YOLOv9?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
